{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%autoreload utils.tag_char\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import yaml\n",
    "\n",
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm import tqdm_pandas\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'date': '0606',\n",
       " 'experiment_name': 'bert_p=0.5_pos=sentence',\n",
       " 'mode': 'BP',\n",
       " 'entity_type': ['Company', 'Person'],\n",
       " 'num_labels': 5,\n",
       " 'threshold': 0.5,\n",
       " 'train_data': '/train_dataset',\n",
       " 'valid_data': '/valid_dataset',\n",
       " 'test_data': '/test_dataset',\n",
       " 'pretrained_model': 'hfl/chinese-roberta-wwm-ext',\n",
       " 'do_training': True,\n",
       " 'max_len': 512,\n",
       " 'batch_size': 32,\n",
       " 'n_epochs': 5,\n",
       " 'lr': '1e-5',\n",
       " 'do_prediction': True}"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../config.yaml\", 'r') as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=32, date='0606', do_prediction=True, do_training=True, entity_type=['Company', 'Person'], experiment_name='bert_p=0.5_pos=sentence', lr='1e-5', max_len=512, mode='BP', n_epochs=5, num_labels=5, prefix_path='../experiments/0606_bert_p=0.5_pos=sentence_BP', pretrained_model='hfl/chinese-roberta-wwm-ext', test_data='/test_dataset', threshold=0.5, train_data='/train_dataset', valid_data='/valid_dataset')"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='') \n",
    "\n",
    "parser.set_defaults(**config)\n",
    "args = parser.parse_args(args = [])\n",
    "\n",
    "parser.add_argument(\"--prefix_path\", type=str, default=f\"../experiments/{args.date}_{args.experiment_name}_{args.mode}\")\n",
    "args = parser.parse_args(args = [])\n",
    "\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0, 'B-Company': 1, 'I-Company': 2, 'B-Person': 3, 'I-Person': 4}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_ids, ids_to_labels = define_labels(param_args=args)\n",
    "labels_to_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立实验文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(args.prefix_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split to train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39593, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>headline</th>\n",
       "      <th>content</th>\n",
       "      <th>ner</th>\n",
       "      <th>matched_keywords</th>\n",
       "      <th>include_company</th>\n",
       "      <th>include_person</th>\n",
       "      <th>length</th>\n",
       "      <th>split_sentence_index</th>\n",
       "      <th>Companys</th>\n",
       "      <th>Persons</th>\n",
       "      <th>context_cleaned</th>\n",
       "      <th>person_matched</th>\n",
       "      <th>company_matched</th>\n",
       "      <th>context_keywords</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023063021774796465&amp;&amp;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。宝申控股(08151) 有关复牌...</td>\n",
       "      <td>[{'label_name': 'Company', 'text_segment': '寶申...</td>\n",
       "      <td>['宝申控股']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>['宝申控股']</td>\n",
       "      <td>[]</td>\n",
       "      <td>宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。宝申控股(08151) 有关复牌...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['宝申控股']</td>\n",
       "      <td>宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。||可能的实体：宝申控股||宝申...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023063021774796485&amp;&amp;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>利骏集团香港(08360) 股东特别大会的结果。利骏集团香港(08360) 于二零二三年六月...</td>\n",
       "      <td>[{'label_name': 'Company', 'text_segment': '利駿...</td>\n",
       "      <td>['利骏集团香港', '东特']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>['利骏集团', '利骏集团香港', '东特']</td>\n",
       "      <td>[]</td>\n",
       "      <td>利骏集团香港(08360) 股东特别大会的结果。利骏集团香港(08360) 于二零二三年六月...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['利骏集团香港', '东特']</td>\n",
       "      <td>利骏集团香港(08360) 股东特别大会的结果。||可能的实体：利骏集团香港,东特||利骏集...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023063021774796605&amp;&amp;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>推进科技自立自强， 国家集成电路设计自动化技术创新中心正式揭牌。21世纪经济报道记者 郭晨 ...</td>\n",
       "      <td>[{'label_name': 'Company', 'text_segment': '21...</td>\n",
       "      <td>['21世纪经济报道', '陈之常', '杨学鹏', '郭晨', '黄如', '徐光辉', ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>488</td>\n",
       "      <td>0</td>\n",
       "      <td>['21世纪经济报道']</td>\n",
       "      <td>['陈之常', '杨学鹏', '郭晨', '黄如', '徐光辉', '胡广杰', '吴刚']</td>\n",
       "      <td>推进科技自立自强， 国家集成电路设计自动化技术创新中心正式揭牌。21世纪经济报道记者 郭晨 ...</td>\n",
       "      <td>['陈之常', '杨学鹏', '郭晨', '黄如', '徐光辉', '胡广杰', '吴刚']</td>\n",
       "      <td>['21世纪经济报道']</td>\n",
       "      <td>推进科技自立自强， 国家集成电路设计自动化技术创新中心正式揭牌。21世纪经济报道记者 郭晨 ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023063021774796605&amp;&amp;1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>江苏省副省长胡广杰对EDA国创中心成立表示祝贺。他说,集成电路产业是我省具有较强竞争力的优势...</td>\n",
       "      <td>[{'label_name': 'Company', 'text_segment': '21...</td>\n",
       "      <td>['陈之常', '胡广杰']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>432</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['陈之常', '胡广杰']</td>\n",
       "      <td>江苏省副省长胡广杰对eda国创中心成立表示祝贺。他说,集成电路产业是我省具有较强竞争力的优势...</td>\n",
       "      <td>['陈之常', '胡广杰']</td>\n",
       "      <td>[]</td>\n",
       "      <td>江苏省副省长胡广杰对eda国创中心成立表示祝贺。||可能的实体：胡广杰||他说,集成电路产业...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    docid  headline  \\\n",
       "0  2023063021774796465&&0       NaN   \n",
       "1  2023063021774796485&&0       NaN   \n",
       "2  2023063021774796605&&0       NaN   \n",
       "3  2023063021774796605&&1       NaN   \n",
       "\n",
       "                                             content  \\\n",
       "0  宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。宝申控股(08151) 有关复牌...   \n",
       "1  利骏集团香港(08360) 股东特别大会的结果。利骏集团香港(08360) 于二零二三年六月...   \n",
       "2  推进科技自立自强， 国家集成电路设计自动化技术创新中心正式揭牌。21世纪经济报道记者 郭晨 ...   \n",
       "3  江苏省副省长胡广杰对EDA国创中心成立表示祝贺。他说,集成电路产业是我省具有较强竞争力的优势...   \n",
       "\n",
       "                                                 ner  \\\n",
       "0  [{'label_name': 'Company', 'text_segment': '寶申...   \n",
       "1  [{'label_name': 'Company', 'text_segment': '利駿...   \n",
       "2  [{'label_name': 'Company', 'text_segment': '21...   \n",
       "3  [{'label_name': 'Company', 'text_segment': '21...   \n",
       "\n",
       "                                    matched_keywords  include_company  \\\n",
       "0                                           ['宝申控股']             True   \n",
       "1                                   ['利骏集团香港', '东特']             True   \n",
       "2  ['21世纪经济报道', '陈之常', '杨学鹏', '郭晨', '黄如', '徐光辉', ...             True   \n",
       "3                                     ['陈之常', '胡广杰']             True   \n",
       "\n",
       "   include_person  length  split_sentence_index                  Companys  \\\n",
       "0            True      74                     0                  ['宝申控股']   \n",
       "1            True      74                     0  ['利骏集团', '利骏集团香港', '东特']   \n",
       "2            True     488                     0              ['21世纪经济报道']   \n",
       "3            True     432                     1                        []   \n",
       "\n",
       "                                          Persons  \\\n",
       "0                                              []   \n",
       "1                                              []   \n",
       "2  ['陈之常', '杨学鹏', '郭晨', '黄如', '徐光辉', '胡广杰', '吴刚']   \n",
       "3                                  ['陈之常', '胡广杰']   \n",
       "\n",
       "                                     context_cleaned  \\\n",
       "0  宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。宝申控股(08151) 有关复牌...   \n",
       "1  利骏集团香港(08360) 股东特别大会的结果。利骏集团香港(08360) 于二零二三年六月...   \n",
       "2  推进科技自立自强， 国家集成电路设计自动化技术创新中心正式揭牌。21世纪经济报道记者 郭晨 ...   \n",
       "3  江苏省副省长胡广杰对eda国创中心成立表示祝贺。他说,集成电路产业是我省具有较强竞争力的优势...   \n",
       "\n",
       "                                   person_matched   company_matched  \\\n",
       "0                                              []          ['宝申控股']   \n",
       "1                                              []  ['利骏集团香港', '东特']   \n",
       "2  ['陈之常', '杨学鹏', '郭晨', '黄如', '徐光辉', '胡广杰', '吴刚']      ['21世纪经济报道']   \n",
       "3                                  ['陈之常', '胡广杰']                []   \n",
       "\n",
       "                                    context_keywords   sign  \n",
       "0  宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。||可能的实体：宝申控股||宝申...  False  \n",
       "1  利骏集团香港(08360) 股东特别大会的结果。||可能的实体：利骏集团香港,东特||利骏集...  False  \n",
       "2  推进科技自立自强， 国家集成电路设计自动化技术创新中心正式揭牌。21世纪经济报道记者 郭晨 ...  False  \n",
       "3  江苏省副省长胡广杰对eda国创中心成立表示祝贺。||可能的实体：胡广杰||他说,集成电路产业...  False  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_data = pd.read_pickle(\"../data/data_starbucks_yihetang_aligned.pkl\")\n",
    "df_data = pd.read_excel(\"../bochk/manual_label_data.xlsx\")\n",
    "print(df_data.shape)\n",
    "df_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_data['person_matched'] = df_data['person_matched'].map(eval)\n",
    "df_data['company_matched'] = df_data['company_matched'].map(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 16)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['sign'] = df_data.apply(lambda row: row['company_matched'].__len__() > 0 or row['person_matched'].__len__() > 0, axis=1)\n",
    "df_data[df_data['sign']==False].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['docid'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31009, 4030, 4554)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df_data[[\"docid\"]])\n",
    "\n",
    "splitted_dataset = dataset.train_test_split(train_size=0.885, seed=109)\n",
    "train_ = splitted_dataset['train']\n",
    "split_ = train_.train_test_split(train_size=0.885, seed=109)\n",
    "\n",
    "train_set = split_['train']\n",
    "valid_set = split_['test']\n",
    "test_set = splitted_dataset['test']\n",
    "\n",
    "len(train_set), len(valid_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(f\"{args.prefix_path}/train_docid.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(train_set['docid']))\n",
    "\n",
    "with open(f\"{args.prefix_path}/valid_docid.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(valid_set['docid']))\n",
    "\n",
    "with open(f\"{args.prefix_path}/test_docid.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(test_set['docid']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>headline</th>\n",
       "      <th>content</th>\n",
       "      <th>ner</th>\n",
       "      <th>matched_keywords</th>\n",
       "      <th>include_company</th>\n",
       "      <th>include_person</th>\n",
       "      <th>length</th>\n",
       "      <th>split_sentence_index</th>\n",
       "      <th>Companys</th>\n",
       "      <th>Persons</th>\n",
       "      <th>context_cleaned</th>\n",
       "      <th>person_matched</th>\n",
       "      <th>company_matched</th>\n",
       "      <th>context_keywords</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023063021774796465&amp;&amp;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。宝申控股(08151) 有关复牌...</td>\n",
       "      <td>[{'label_name': 'Company', 'text_segment': '寶申...</td>\n",
       "      <td>['宝申控股']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>['宝申控股']</td>\n",
       "      <td>[]</td>\n",
       "      <td>宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。宝申控股(08151) 有关复牌...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[宝申控股]</td>\n",
       "      <td>宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。||可能的实体：宝申控股||宝申...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    docid  headline  \\\n",
       "0  2023063021774796465&&0       NaN   \n",
       "\n",
       "                                             content  \\\n",
       "0  宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。宝申控股(08151) 有关复牌...   \n",
       "\n",
       "                                                 ner matched_keywords  \\\n",
       "0  [{'label_name': 'Company', 'text_segment': '寶申...         ['宝申控股']   \n",
       "\n",
       "   include_company  include_person  length  split_sentence_index  Companys  \\\n",
       "0             True            True      74                     0  ['宝申控股']   \n",
       "\n",
       "  Persons                                    context_cleaned person_matched  \\\n",
       "0      []  宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。宝申控股(08151) 有关复牌...             []   \n",
       "\n",
       "  company_matched                                   context_keywords   sign  \n",
       "0          [宝申控股]  宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。||可能的实体：宝申控股||宝申...  False  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_all = pd.read_excel(\"../bochk/manual_label_data.xlsx\")\n",
    "df_all['person_matched'] = df_all['person_matched'].map(eval)\n",
    "df_all['company_matched'] = df_all['company_matched'].map(eval)\n",
    "df_all['content'] = df_all['content'].astype(str)\n",
    "df_all.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>headline</th>\n",
       "      <th>content</th>\n",
       "      <th>ner</th>\n",
       "      <th>matched_keywords</th>\n",
       "      <th>include_company</th>\n",
       "      <th>include_person</th>\n",
       "      <th>length</th>\n",
       "      <th>split_sentence_index</th>\n",
       "      <th>Companys</th>\n",
       "      <th>Persons</th>\n",
       "      <th>context_cleaned</th>\n",
       "      <th>person_matched</th>\n",
       "      <th>company_matched</th>\n",
       "      <th>context_keywords</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39588</th>\n",
       "      <td>998&amp;&amp;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>原标题：多城“人才争夺战” 房地产市场格局难变。“二十一世纪什么最贵。人才。”直至十余年后，...</td>\n",
       "      <td>[{'label_name': 'Time', 'text_segment': '二十一世紀...</td>\n",
       "      <td>['方米']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>489</td>\n",
       "      <td>0</td>\n",
       "      <td>['方米']</td>\n",
       "      <td>[]</td>\n",
       "      <td>原标题：多城“人才争夺战” 房地产市场格局难变。“二十一世纪什么最贵。人才。”直至十余年后，...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[方米]</td>\n",
       "      <td>原标题：多城“人才争夺战” 房地产市场格局难变。“二十一世纪什么最贵。人才。”直至十余年后，...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39589</th>\n",
       "      <td>998&amp;&amp;1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>工作期间保障交通工具。无独有偶。博州人才政策对于住房方面的关注在其他三四五线城市动作中也有所...</td>\n",
       "      <td>[{'label_name': 'Time', 'text_segment': '二十一世紀...</td>\n",
       "      <td>['国际金融报', '交通', '工程', '易居研究院智库中心', '严跃进']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>493</td>\n",
       "      <td>1</td>\n",
       "      <td>['工程', '国际金融报', '易居研究院智库中心', '易居', '交通', '易居研究院']</td>\n",
       "      <td>['严跃进']</td>\n",
       "      <td>工作期间保障交通工具。无独有偶。博州人才政策对于住房方面的关注在其他三四五线城市动作中也有所...</td>\n",
       "      <td>[严跃进]</td>\n",
       "      <td>[国际金融报, 交通, 工程, 易居研究院智库中心]</td>\n",
       "      <td>工作期间保障交通工具。||可能的实体：交通||无独有偶。博州人才政策对于住房方面的关注在其他...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39590</th>\n",
       "      <td>998&amp;&amp;2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>这场对于人才的竞争已不再局限于城市之间。“战火”已悄悄弥漫至区、县等更小的行政单位。不过，一...</td>\n",
       "      <td>[{'label_name': 'Time', 'text_segment': '二十一世紀...</td>\n",
       "      <td>['国际金融报']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>447</td>\n",
       "      <td>2</td>\n",
       "      <td>['国际金融报']</td>\n",
       "      <td>[]</td>\n",
       "      <td>这场对于人才的竞争已不再局限于城市之间。“战火”已悄悄弥漫至区、县等更小的行政单位。不过，一...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[国际金融报]</td>\n",
       "      <td>这场对于人才的竞争已不再局限于城市之间。“战火”已悄悄弥漫至区、县等更小的行政单位。不过，一...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39591</th>\n",
       "      <td>998&amp;&amp;3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3月18日，河北石家庄推动户口迁入“零门槛”，群众仅凭居民身份证、户口簿就可向落户地派出所申...</td>\n",
       "      <td>[{'label_name': 'Time', 'text_segment': '二十一世紀...</td>\n",
       "      <td>['易居', '方米', '严跃进', '沈路']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>496</td>\n",
       "      <td>3</td>\n",
       "      <td>['易居', '方米']</td>\n",
       "      <td>['严跃进', '沈路']</td>\n",
       "      <td>3月18日，河北石家庄推动户口迁入“零门槛”，群众仅凭居民身份证、户口簿就可向落户地派出所申...</td>\n",
       "      <td>[严跃进, 沈路]</td>\n",
       "      <td>[易居, 方米]</td>\n",
       "      <td>3月18日，河北石家庄推动户口迁入“零门槛”，群众仅凭居民身份证、户口簿就可向落户地派出所申...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39592</th>\n",
       "      <td>998&amp;&amp;4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>中大城市的人才济济和持续人口聚集效应留给小城市的或是人口流出的落寞。易居研究院研究员沈昕对记...</td>\n",
       "      <td>[{'label_name': 'Time', 'text_segment': '二十一世紀...</td>\n",
       "      <td>['易居研究院', '国际金融报', '搜狐', '陈晨', '刘民', '刘明', '沈昕']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>486</td>\n",
       "      <td>4</td>\n",
       "      <td>['国际金融报', '搜狐', '易居', '易居研究院']</td>\n",
       "      <td>['陈晨', '刘民', '刘明', '沈昕']</td>\n",
       "      <td>中大城市的人才济济和持续人口聚集效应留给小城市的或是人口流出的落寞。易居研究院研究员沈昕对记...</td>\n",
       "      <td>[陈晨, 刘民, 刘明, 沈昕]</td>\n",
       "      <td>[易居研究院, 国际金融报, 搜狐]</td>\n",
       "      <td>中大城市的人才济济和持续人口聚集效应留给小城市的或是人口流出的落寞。易居研究院研究员沈昕对记...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        docid  headline                                            content  \\\n",
       "39588  998&&0       NaN  原标题：多城“人才争夺战” 房地产市场格局难变。“二十一世纪什么最贵。人才。”直至十余年后，...   \n",
       "39589  998&&1       NaN  工作期间保障交通工具。无独有偶。博州人才政策对于住房方面的关注在其他三四五线城市动作中也有所...   \n",
       "39590  998&&2       NaN  这场对于人才的竞争已不再局限于城市之间。“战火”已悄悄弥漫至区、县等更小的行政单位。不过，一...   \n",
       "39591  998&&3       NaN  3月18日，河北石家庄推动户口迁入“零门槛”，群众仅凭居民身份证、户口簿就可向落户地派出所申...   \n",
       "39592  998&&4       NaN  中大城市的人才济济和持续人口聚集效应留给小城市的或是人口流出的落寞。易居研究院研究员沈昕对记...   \n",
       "\n",
       "                                                     ner  \\\n",
       "39588  [{'label_name': 'Time', 'text_segment': '二十一世紀...   \n",
       "39589  [{'label_name': 'Time', 'text_segment': '二十一世紀...   \n",
       "39590  [{'label_name': 'Time', 'text_segment': '二十一世紀...   \n",
       "39591  [{'label_name': 'Time', 'text_segment': '二十一世紀...   \n",
       "39592  [{'label_name': 'Time', 'text_segment': '二十一世紀...   \n",
       "\n",
       "                                       matched_keywords  include_company  \\\n",
       "39588                                            ['方米']             True   \n",
       "39589         ['国际金融报', '交通', '工程', '易居研究院智库中心', '严跃进']             True   \n",
       "39590                                         ['国际金融报']             True   \n",
       "39591                         ['易居', '方米', '严跃进', '沈路']             True   \n",
       "39592  ['易居研究院', '国际金融报', '搜狐', '陈晨', '刘民', '刘明', '沈昕']             True   \n",
       "\n",
       "       include_person  length  split_sentence_index  \\\n",
       "39588            True     489                     0   \n",
       "39589            True     493                     1   \n",
       "39590            True     447                     2   \n",
       "39591            True     496                     3   \n",
       "39592            True     486                     4   \n",
       "\n",
       "                                                Companys  \\\n",
       "39588                                             ['方米']   \n",
       "39589  ['工程', '国际金融报', '易居研究院智库中心', '易居', '交通', '易居研究院']   \n",
       "39590                                          ['国际金融报']   \n",
       "39591                                       ['易居', '方米']   \n",
       "39592                     ['国际金融报', '搜狐', '易居', '易居研究院']   \n",
       "\n",
       "                        Persons  \\\n",
       "39588                        []   \n",
       "39589                   ['严跃进']   \n",
       "39590                        []   \n",
       "39591             ['严跃进', '沈路']   \n",
       "39592  ['陈晨', '刘民', '刘明', '沈昕']   \n",
       "\n",
       "                                         context_cleaned    person_matched  \\\n",
       "39588  原标题：多城“人才争夺战” 房地产市场格局难变。“二十一世纪什么最贵。人才。”直至十余年后，...                []   \n",
       "39589  工作期间保障交通工具。无独有偶。博州人才政策对于住房方面的关注在其他三四五线城市动作中也有所...             [严跃进]   \n",
       "39590  这场对于人才的竞争已不再局限于城市之间。“战火”已悄悄弥漫至区、县等更小的行政单位。不过，一...                []   \n",
       "39591  3月18日，河北石家庄推动户口迁入“零门槛”，群众仅凭居民身份证、户口簿就可向落户地派出所申...         [严跃进, 沈路]   \n",
       "39592  中大城市的人才济济和持续人口聚集效应留给小城市的或是人口流出的落寞。易居研究院研究员沈昕对记...  [陈晨, 刘民, 刘明, 沈昕]   \n",
       "\n",
       "                  company_matched  \\\n",
       "39588                        [方米]   \n",
       "39589  [国际金融报, 交通, 工程, 易居研究院智库中心]   \n",
       "39590                     [国际金融报]   \n",
       "39591                    [易居, 方米]   \n",
       "39592          [易居研究院, 国际金融报, 搜狐]   \n",
       "\n",
       "                                        context_keywords   sign  \n",
       "39588  原标题：多城“人才争夺战” 房地产市场格局难变。“二十一世纪什么最贵。人才。”直至十余年后，...  False  \n",
       "39589  工作期间保障交通工具。||可能的实体：交通||无独有偶。博州人才政策对于住房方面的关注在其他...  False  \n",
       "39590  这场对于人才的竞争已不再局限于城市之间。“战火”已悄悄弥漫至区、县等更小的行政单位。不过，一...  False  \n",
       "39591  3月18日，河北石家庄推动户口迁入“零门槛”，群众仅凭居民身份证、户口簿就可向落户地派出所申...  False  \n",
       "39592  中大城市的人才济济和持续人口聚集效应留给小城市的或是人口流出的落寞。易居研究院研究员沈昕对记...  False  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>headline</th>\n",
       "      <th>content</th>\n",
       "      <th>ner</th>\n",
       "      <th>matched_keywords</th>\n",
       "      <th>include_company</th>\n",
       "      <th>include_person</th>\n",
       "      <th>length</th>\n",
       "      <th>split_sentence_index</th>\n",
       "      <th>Companys</th>\n",
       "      <th>Persons</th>\n",
       "      <th>context_cleaned</th>\n",
       "      <th>person_matched</th>\n",
       "      <th>company_matched</th>\n",
       "      <th>context_keywords</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39590</th>\n",
       "      <td>998&amp;&amp;2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>这场对于人才的竞争已不再局限于城市之间。“战火”已悄悄弥漫至区、县等更小的行政单位。不过，一...</td>\n",
       "      <td>[{'label_name': 'Time', 'text_segment': '二十一世紀...</td>\n",
       "      <td>['国际金融报']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>447</td>\n",
       "      <td>2</td>\n",
       "      <td>['国际金融报']</td>\n",
       "      <td>[]</td>\n",
       "      <td>这场对于人才的竞争已不再局限于城市之间。“战火”已悄悄弥漫至区、县等更小的行政单位。不过，一...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[国际金融报]</td>\n",
       "      <td>这场对于人才的竞争已不再局限于城市之间。“战火”已悄悄弥漫至区、县等更小的行政单位。不过，一...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        docid  headline                                            content  \\\n",
       "39590  998&&2       NaN  这场对于人才的竞争已不再局限于城市之间。“战火”已悄悄弥漫至区、县等更小的行政单位。不过，一...   \n",
       "\n",
       "                                                     ner matched_keywords  \\\n",
       "39590  [{'label_name': 'Time', 'text_segment': '二十一世紀...        ['国际金融报']   \n",
       "\n",
       "       include_company  include_person  length  split_sentence_index  \\\n",
       "39590             True            True     447                     2   \n",
       "\n",
       "        Companys Persons                                    context_cleaned  \\\n",
       "39590  ['国际金融报']      []  这场对于人才的竞争已不再局限于城市之间。“战火”已悄悄弥漫至区、县等更小的行政单位。不过，一...   \n",
       "\n",
       "      person_matched company_matched  \\\n",
       "39590             []         [国际金融报]   \n",
       "\n",
       "                                        context_keywords   sign  \n",
       "39590  这场对于人才的竞争已不再局限于城市之间。“战火”已悄悄弥漫至区、县等更小的行政单位。不过，一...  False  "
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[df_all['docid'] == '998&&2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all['docid'].is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31009, 4030, 4554)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"{args.prefix_path}/train_docid.txt\", \"r\") as f:\n",
    "    train_docid = f.read().split(\"\\n\")\n",
    "\n",
    "with open(f\"{args.prefix_path}/valid_docid.txt\", \"r\") as f:\n",
    "    valid_docid = f.read().split(\"\\n\")\n",
    "\n",
    "with open(f\"{args.prefix_path}/test_docid.txt\", \"r\") as f:\n",
    "    test_docid = f.read().split(\"\\n\")\n",
    "\n",
    "len(train_docid), len(valid_docid), len(test_docid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31009, 4030, 4554)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_all[df_all[\"docid\"].isin(train_docid)].reset_index(drop=True)\n",
    "df_valid = df_all[df_all[\"docid\"].isin(valid_docid)].reset_index(drop=True)\n",
    "df_test = df_all[df_all[\"docid\"].isin(test_docid)].reset_index(drop=True)\n",
    "\n",
    "len(df_train), len(df_valid), len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.threshold == 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df_train[\"input_text\"] = df_train.apply(lambda x: x[\"context_keywords\"] if np.random.random()>args.threshold else x[\"context_cleaned\"], axis = 1)\n",
    "df_valid[\"input_text\"] = df_valid.apply(lambda x: x[\"context_keywords\"] if np.random.random()>args.threshold else x[\"context_cleaned\"], axis = 1)\n",
    "\n",
    "df_train['input_text'] = df_train['context_cleaned']\n",
    "df_valid['input_text'] = df_valid['context_cleaned']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.媒体来源:。apple。2.完整新闻标题:。血汗。海瑞扛丸宁受罚 不给员工加班费。3.完整新闻内文:。新竹十大伴手礼海瑞扛丸遭2员工爆料,指控压榨劳工。一名洪小姐控说,公司让她们超时。工作,加班还没有加班费,只给原本时薪115元,还要她们签下“不得要求加班费”的同意。书,让她觉得非常痛苦,且目前全体员工都采时薪制,一旦遇到小月,员工的薪水就少得可。怜。“公司宁被劳工局开罚,也不肯给我9千块加班费”洪小姐声泪俱下控诉,依劳基法规定员。工一天上班时数为8小时,超过时数必须按照比例支付加班费,公司时常要求他们加班12小。时,但超出来的时数,未依规定加给,只采取支付每小时115元。非但如此,全体员工劳健。保还被低报,目前已被劳工局开罚。当初跟公司调解争取加班费时,公司竟回应说:“你早就知道要加班了,为什么还要加班费。”还呛她:“反正公司已经被罚钱了。”不合理言论让黄小姐哭笑不得。洪小姐说,公司。还要求每个人签“不平等条约”,要他们同意加班,但没有加班费。洪小姐控诉,海瑞扛丸的上司把他们当司机,要求他们骑车或开车载他到火车站或市政府,'"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[5556, 'input_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'利骏集团香港(08360) 股东特别大会的结果。利骏集团香港(08360) 于二零二三年六月三十日举行的股东特别大会投票结果(112kb, pdf)'"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[1, 'input_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['docid', 'headline', 'content', 'ner', 'matched_keywords',\n",
       "       'include_company', 'include_person', 'length', 'split_sentence_index',\n",
       "       'Companys', 'Persons', 'context_cleaned', 'person_matched',\n",
       "       'company_matched', 'context_keywords', 'sign', 'input_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tag char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tag_char(df, args):\n",
    "    def _tag_char(example, param_args):\n",
    "        content = example['input_text'] if pd.notna(example['input_text']) else \"\"\n",
    "        try:\n",
    "            tag = ['O'] * len(str(content))\n",
    "\n",
    "            for entity_type in param_args.entity_type:\n",
    "                pos_list = []\n",
    "                entity_list = example[f\"{entity_type}_matched\".lower()]\n",
    "                if entity_list == []:\n",
    "                    continue\n",
    "                else:\n",
    "                    for entity in entity_list:\n",
    "                        # try:\n",
    "                        #     pos_list.extend([(match.start(), match.end()) for match in re.finditer(entity, content)])\n",
    "                        # except Exception as e:\n",
    "                        #     print(entity, content)\n",
    "                        #     continue\n",
    "                        try:\n",
    "                            pos_list.extend([(match.start(), match.end()) for match in re.finditer(entity, content)])\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                            continue\n",
    "                    for (start, end) in pos_list:\n",
    "                        tag[start] = f\"B-{entity_type}\"\n",
    "                        tag[start+1:end] = [f\"I-{entity_type}\"] * (end - start - 1)\n",
    "\n",
    "            assert len(content) == len(tag)\n",
    "            return tag\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    tqdm.pandas(desc='tagging char-level label')\n",
    "    df['tag_char'] = df.apply(_tag_char, param_args=args, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing ), unterminated subpattern at position 13\n",
      "nothing to repeat at position 0\n",
      "unterminated character set at position 0\n",
      "missing ), unterminated subpattern at position 0\n",
      "missing ), unterminated subpattern at position 0\n",
      "expected string or bytes-like object\n",
      "expected string or bytes-like object\n",
      "expected string or bytes-like object\n",
      "expected string or bytes-like object\n",
      "expected string or bytes-like object\n",
      "expected string or bytes-like object\n",
      "missing ), unterminated subpattern at position 0\n",
      "missing ), unterminated subpattern at position 0\n",
      "nothing to repeat at position 0\n",
      "nothing to repeat at position 0\n",
      "nothing to repeat at position 0\n",
      "nothing to repeat at position 0\n",
      "nothing to repeat at position 0\n",
      "unbalanced parenthesis at position 32\n",
      "missing ), unterminated subpattern at position 4\n",
      "missing ), unterminated subpattern at position 0\n",
      "missing ), unterminated subpattern at position 0\n",
      "missing ), unterminated subpattern at position 0\n",
      "missing ), unterminated subpattern at position 0\n",
      "missing ), unterminated subpattern at position 0\n",
      "missing ), unterminated subpattern at position 0\n",
      "missing ), unterminated subpattern at position 0\n",
      "missing ), unterminated subpattern at position 0\n",
      "missing ), unterminated subpattern at position 0\n",
      "missing ), unterminated subpattern at position 0\n",
      "missing ), unterminated subpattern at position 9\n",
      "nothing to repeat at position 0\n",
      "expected string or bytes-like object\n",
      "missing ), unterminated subpattern at position 0\n",
      "missing ), unterminated subpattern at position 12\n",
      "multiple repeat at position 5\n",
      "multiple repeat at position 5\n",
      "multiple repeat at position 5\n",
      "missing ), unterminated subpattern at position 0\n",
      "missing ), unterminated subpattern at position 0\n",
      "nothing to repeat at position 0\n",
      "nothing to repeat at position 0\n",
      "missing ), unterminated subpattern at position 8\n",
      "missing ), unterminated subpattern at position 8\n",
      "missing ), unterminated subpattern at position 8\n",
      "missing ), unterminated subpattern at position 8\n",
      "nothing to repeat at position 0\n"
     ]
    }
   ],
   "source": [
    "df_train = tag_char(df_train, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_train[df_train['docid']=='995&&2'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unbalanced parenthesis at position 10\n",
      "missing ), unterminated subpattern at position 0\n",
      "missing ), unterminated subpattern at position 0\n",
      "nothing to repeat at position 0\n",
      "missing ), unterminated subpattern at position 0\n",
      "unbalanced parenthesis at position 16\n"
     ]
    }
   ],
   "source": [
    "df_valid = tag_char(df_valid, args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokenize and align label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31009, 18)\n",
      "(31006, 18)\n",
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892d0c66ea874519be48048c922dffaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=969), Label(value='0 / 969'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>headline</th>\n",
       "      <th>content</th>\n",
       "      <th>ner</th>\n",
       "      <th>matched_keywords</th>\n",
       "      <th>include_company</th>\n",
       "      <th>include_person</th>\n",
       "      <th>length</th>\n",
       "      <th>split_sentence_index</th>\n",
       "      <th>Companys</th>\n",
       "      <th>Persons</th>\n",
       "      <th>context_cleaned</th>\n",
       "      <th>person_matched</th>\n",
       "      <th>company_matched</th>\n",
       "      <th>context_keywords</th>\n",
       "      <th>sign</th>\n",
       "      <th>input_text</th>\n",
       "      <th>tag_char</th>\n",
       "      <th>tokenized_content</th>\n",
       "      <th>token_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023063021774796465&amp;&amp;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。宝申控股(08151) 有关复牌...</td>\n",
       "      <td>[{'label_name': 'Company', 'text_segment': '寶申...</td>\n",
       "      <td>['宝申控股']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>['宝申控股']</td>\n",
       "      <td>[]</td>\n",
       "      <td>宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。宝申控股(08151) 有关复牌...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[宝申控股]</td>\n",
       "      <td>宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。||可能的实体：宝申控股||宝申...</td>\n",
       "      <td>False</td>\n",
       "      <td>宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。宝申控股(08151) 有关复牌...</td>\n",
       "      <td>[B-Company, I-Company, I-Company, I-Company, O...</td>\n",
       "      <td>[宝, 申, 控, 股, (, 0, 8, 1, 5, 1, ), 停, 牌, /, 内, ...</td>\n",
       "      <td>[B-Company, I-Company, I-Company, I-Company, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023063021774796485&amp;&amp;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>利骏集团香港(08360) 股东特别大会的结果。利骏集团香港(08360) 于二零二三年六月...</td>\n",
       "      <td>[{'label_name': 'Company', 'text_segment': '利駿...</td>\n",
       "      <td>['利骏集团香港', '东特']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>['利骏集团', '利骏集团香港', '东特']</td>\n",
       "      <td>[]</td>\n",
       "      <td>利骏集团香港(08360) 股东特别大会的结果。利骏集团香港(08360) 于二零二三年六月...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[利骏集团香港, 东特]</td>\n",
       "      <td>利骏集团香港(08360) 股东特别大会的结果。||可能的实体：利骏集团香港,东特||利骏集...</td>\n",
       "      <td>False</td>\n",
       "      <td>利骏集团香港(08360) 股东特别大会的结果。利骏集团香港(08360) 于二零二三年六月...</td>\n",
       "      <td>[B-Company, I-Company, I-Company, I-Company, I...</td>\n",
       "      <td>[利, 骏, 集, 团, 香, 港, (, 0, 8, 3, 6, 0, ), 股, 东, ...</td>\n",
       "      <td>[B-Company, I-Company, I-Company, I-Company, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023063021774796605&amp;&amp;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>推进科技自立自强， 国家集成电路设计自动化技术创新中心正式揭牌。21世纪经济报道记者 郭晨 ...</td>\n",
       "      <td>[{'label_name': 'Company', 'text_segment': '21...</td>\n",
       "      <td>['21世纪经济报道', '陈之常', '杨学鹏', '郭晨', '黄如', '徐光辉', ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>488</td>\n",
       "      <td>0</td>\n",
       "      <td>['21世纪经济报道']</td>\n",
       "      <td>['陈之常', '杨学鹏', '郭晨', '黄如', '徐光辉', '胡广杰', '吴刚']</td>\n",
       "      <td>推进科技自立自强， 国家集成电路设计自动化技术创新中心正式揭牌。21世纪经济报道记者 郭晨 ...</td>\n",
       "      <td>[陈之常, 杨学鹏, 郭晨, 黄如, 徐光辉, 胡广杰, 吴刚]</td>\n",
       "      <td>[21世纪经济报道]</td>\n",
       "      <td>推进科技自立自强， 国家集成电路设计自动化技术创新中心正式揭牌。21世纪经济报道记者 郭晨 ...</td>\n",
       "      <td>False</td>\n",
       "      <td>推进科技自立自强， 国家集成电路设计自动化技术创新中心正式揭牌。21世纪经济报道记者 郭晨 ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[推, 进, 科, 技, 自, 立, 自, 强, ，, 国, 家, 集, 成, 电, 路, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    docid  headline  \\\n",
       "0  2023063021774796465&&0       NaN   \n",
       "1  2023063021774796485&&0       NaN   \n",
       "2  2023063021774796605&&0       NaN   \n",
       "\n",
       "                                             content  \\\n",
       "0  宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。宝申控股(08151) 有关复牌...   \n",
       "1  利骏集团香港(08360) 股东特别大会的结果。利骏集团香港(08360) 于二零二三年六月...   \n",
       "2  推进科技自立自强， 国家集成电路设计自动化技术创新中心正式揭牌。21世纪经济报道记者 郭晨 ...   \n",
       "\n",
       "                                                 ner  \\\n",
       "0  [{'label_name': 'Company', 'text_segment': '寶申...   \n",
       "1  [{'label_name': 'Company', 'text_segment': '利駿...   \n",
       "2  [{'label_name': 'Company', 'text_segment': '21...   \n",
       "\n",
       "                                    matched_keywords  include_company  \\\n",
       "0                                           ['宝申控股']             True   \n",
       "1                                   ['利骏集团香港', '东特']             True   \n",
       "2  ['21世纪经济报道', '陈之常', '杨学鹏', '郭晨', '黄如', '徐光辉', ...             True   \n",
       "\n",
       "   include_person  length  split_sentence_index                  Companys  \\\n",
       "0            True      74                     0                  ['宝申控股']   \n",
       "1            True      74                     0  ['利骏集团', '利骏集团香港', '东特']   \n",
       "2            True     488                     0              ['21世纪经济报道']   \n",
       "\n",
       "                                          Persons  \\\n",
       "0                                              []   \n",
       "1                                              []   \n",
       "2  ['陈之常', '杨学鹏', '郭晨', '黄如', '徐光辉', '胡广杰', '吴刚']   \n",
       "\n",
       "                                     context_cleaned  \\\n",
       "0  宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。宝申控股(08151) 有关复牌...   \n",
       "1  利骏集团香港(08360) 股东特别大会的结果。利骏集团香港(08360) 于二零二三年六月...   \n",
       "2  推进科技自立自强， 国家集成电路设计自动化技术创新中心正式揭牌。21世纪经济报道记者 郭晨 ...   \n",
       "\n",
       "                     person_matched company_matched  \\\n",
       "0                                []          [宝申控股]   \n",
       "1                                []    [利骏集团香港, 东特]   \n",
       "2  [陈之常, 杨学鹏, 郭晨, 黄如, 徐光辉, 胡广杰, 吴刚]      [21世纪经济报道]   \n",
       "\n",
       "                                    context_keywords   sign  \\\n",
       "0  宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。||可能的实体：宝申控股||宝申...  False   \n",
       "1  利骏集团香港(08360) 股东特别大会的结果。||可能的实体：利骏集团香港,东特||利骏集...  False   \n",
       "2  推进科技自立自强， 国家集成电路设计自动化技术创新中心正式揭牌。21世纪经济报道记者 郭晨 ...  False   \n",
       "\n",
       "                                          input_text  \\\n",
       "0  宝申控股(08151) 停牌 / 内幕消息 / 其他-杂项。宝申控股(08151) 有关复牌...   \n",
       "1  利骏集团香港(08360) 股东特别大会的结果。利骏集团香港(08360) 于二零二三年六月...   \n",
       "2  推进科技自立自强， 国家集成电路设计自动化技术创新中心正式揭牌。21世纪经济报道记者 郭晨 ...   \n",
       "\n",
       "                                            tag_char  \\\n",
       "0  [B-Company, I-Company, I-Company, I-Company, O...   \n",
       "1  [B-Company, I-Company, I-Company, I-Company, I...   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                   tokenized_content  \\\n",
       "0  [宝, 申, 控, 股, (, 0, 8, 1, 5, 1, ), 停, 牌, /, 内, ...   \n",
       "1  [利, 骏, 集, 团, 香, 港, (, 0, 8, 3, 6, 0, ), 股, 东, ...   \n",
       "2  [推, 进, 科, 技, 自, 立, 自, 强, ，, 国, 家, 集, 成, 电, 路, ...   \n",
       "\n",
       "                                        token_labels  \n",
       "0  [B-Company, I-Company, I-Company, I-Company, O...  \n",
       "1  [B-Company, I-Company, I-Company, I-Company, I...  \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "df_train = df_train[~df_train['tag_char'].isna()]\n",
    "print(df_train.shape)\n",
    "df_train = tokenize_and_align_labels(df_train, args)\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4030, 18)\n",
      "(4030, 18)\n",
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a649bdde40194c4f9077eef4bccbbeeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=126), Label(value='0 / 126'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>headline</th>\n",
       "      <th>content</th>\n",
       "      <th>ner</th>\n",
       "      <th>matched_keywords</th>\n",
       "      <th>include_company</th>\n",
       "      <th>include_person</th>\n",
       "      <th>length</th>\n",
       "      <th>split_sentence_index</th>\n",
       "      <th>Companys</th>\n",
       "      <th>Persons</th>\n",
       "      <th>context_cleaned</th>\n",
       "      <th>person_matched</th>\n",
       "      <th>company_matched</th>\n",
       "      <th>context_keywords</th>\n",
       "      <th>sign</th>\n",
       "      <th>input_text</th>\n",
       "      <th>tag_char</th>\n",
       "      <th>tokenized_content</th>\n",
       "      <th>token_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023063021774797862&amp;&amp;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>黑芝麻智能成首间特专科企申请上市 芯片依赖台积电制造。黑芝麻智能成首间特专科企申请上市 芯片...</td>\n",
       "      <td>[{'label_name': 'Company', 'text_segment': '黑芝...</td>\n",
       "      <td>['台积电', '小米', '中金', '自动', '黑芝麻智能', '腾讯', '388'...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>498</td>\n",
       "      <td>0</td>\n",
       "      <td>['台积电', '黑芝麻', '小米', '中金', '自动', '黑芝麻智能', '腾讯'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>黑芝麻智能成首间特专科企申请上市 芯片依赖台积电制造。黑芝麻智能成首间特专科企申请上市 芯片...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[台积电, 小米, 中金, 自动, 黑芝麻智能, 腾讯, 388, 华泰国际, SoC]</td>\n",
       "      <td>黑芝麻智能成首间特专科企申请上市 芯片依赖台积电制造。||可能的实体：台积电,黑芝麻智能||...</td>\n",
       "      <td>False</td>\n",
       "      <td>黑芝麻智能成首间特专科企申请上市 芯片依赖台积电制造。黑芝麻智能成首间特专科企申请上市 芯片...</td>\n",
       "      <td>[B-Company, I-Company, I-Company, I-Company, I...</td>\n",
       "      <td>[黑, 芝, 麻, 智, 能, 成, 首, 间, 特, 专, 科, 企, 申, 请, 上, ...</td>\n",
       "      <td>[B-Company, I-Company, I-Company, I-Company, I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023063021774807700&amp;&amp;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>俊盟国际(08062) 财务报表/环境、社会及管治资料 - [年报 / 环境、社会及管治资料...</td>\n",
       "      <td>[{'label_name': 'Company', 'text_segment': '俊盟...</td>\n",
       "      <td>['俊盟国际']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>['俊盟国际']</td>\n",
       "      <td>[]</td>\n",
       "      <td>俊盟国际(08062) 财务报表/环境、社会及管治资料 - [年报 / 环境、社会及管治资料...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[俊盟国际]</td>\n",
       "      <td>俊盟国际(08062) 财务报表/环境、社会及管治资料 - [年报 / 环境、社会及管治资料...</td>\n",
       "      <td>False</td>\n",
       "      <td>俊盟国际(08062) 财务报表/环境、社会及管治资料 - [年报 / 环境、社会及管治资料...</td>\n",
       "      <td>[B-Company, I-Company, I-Company, I-Company, O...</td>\n",
       "      <td>[俊, 盟, 国, 际, (, 0, 8, 0, 6, 2, ), 财, 务, 报, 表, ...</td>\n",
       "      <td>[B-Company, I-Company, I-Company, I-Company, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023063021774822209&amp;&amp;0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>热辣新盘放送｜明隽首轮推售34伙 连天台特色户率先招标沽。热辣新盘放送｜明隽首轮推售34伙 ...</td>\n",
       "      <td>[{'label_name': 'Company', 'text_segment': '佳明...</td>\n",
       "      <td>['佳明集团', '中原', '明隽', '陈永杰']</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>['佳明集团', '中原', '明隽']</td>\n",
       "      <td>['陈永杰']</td>\n",
       "      <td>热辣新盘放送｜明隽首轮推售34伙 连天台特色户率先招标沽。热辣新盘放送｜明隽首轮推售34伙 ...</td>\n",
       "      <td>[陈永杰]</td>\n",
       "      <td>[佳明集团, 中原, 明隽]</td>\n",
       "      <td>热辣新盘放送｜明隽首轮推售34伙 连天台特色户率先招标沽。||可能的实体：明隽||热辣新盘放...</td>\n",
       "      <td>False</td>\n",
       "      <td>热辣新盘放送｜明隽首轮推售34伙 连天台特色户率先招标沽。热辣新盘放送｜明隽首轮推售34伙 ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-Company, I-Company, O,...</td>\n",
       "      <td>[热, 辣, 新, 盘, 放, 送, ｜, 明, 隽, 首, 轮, 推, 售, 3, 4, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, B-Company, I-Company, O,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    docid  headline  \\\n",
       "0  2023063021774797862&&0       NaN   \n",
       "1  2023063021774807700&&0       NaN   \n",
       "2  2023063021774822209&&0       NaN   \n",
       "\n",
       "                                             content  \\\n",
       "0  黑芝麻智能成首间特专科企申请上市 芯片依赖台积电制造。黑芝麻智能成首间特专科企申请上市 芯片...   \n",
       "1  俊盟国际(08062) 财务报表/环境、社会及管治资料 - [年报 / 环境、社会及管治资料...   \n",
       "2  热辣新盘放送｜明隽首轮推售34伙 连天台特色户率先招标沽。热辣新盘放送｜明隽首轮推售34伙 ...   \n",
       "\n",
       "                                                 ner  \\\n",
       "0  [{'label_name': 'Company', 'text_segment': '黑芝...   \n",
       "1  [{'label_name': 'Company', 'text_segment': '俊盟...   \n",
       "2  [{'label_name': 'Company', 'text_segment': '佳明...   \n",
       "\n",
       "                                    matched_keywords  include_company  \\\n",
       "0  ['台积电', '小米', '中金', '自动', '黑芝麻智能', '腾讯', '388'...             True   \n",
       "1                                           ['俊盟国际']             True   \n",
       "2                        ['佳明集团', '中原', '明隽', '陈永杰']             True   \n",
       "\n",
       "   include_person  length  split_sentence_index  \\\n",
       "0            True     498                     0   \n",
       "1            True      80                     0   \n",
       "2            True     239                     0   \n",
       "\n",
       "                                            Companys  Persons  \\\n",
       "0  ['台积电', '黑芝麻', '小米', '中金', '自动', '黑芝麻智能', '腾讯'...       []   \n",
       "1                                           ['俊盟国际']       []   \n",
       "2                               ['佳明集团', '中原', '明隽']  ['陈永杰']   \n",
       "\n",
       "                                     context_cleaned person_matched  \\\n",
       "0  黑芝麻智能成首间特专科企申请上市 芯片依赖台积电制造。黑芝麻智能成首间特专科企申请上市 芯片...             []   \n",
       "1  俊盟国际(08062) 财务报表/环境、社会及管治资料 - [年报 / 环境、社会及管治资料...             []   \n",
       "2  热辣新盘放送｜明隽首轮推售34伙 连天台特色户率先招标沽。热辣新盘放送｜明隽首轮推售34伙 ...          [陈永杰]   \n",
       "\n",
       "                                company_matched  \\\n",
       "0  [台积电, 小米, 中金, 自动, 黑芝麻智能, 腾讯, 388, 华泰国际, SoC]   \n",
       "1                                        [俊盟国际]   \n",
       "2                                [佳明集团, 中原, 明隽]   \n",
       "\n",
       "                                    context_keywords   sign  \\\n",
       "0  黑芝麻智能成首间特专科企申请上市 芯片依赖台积电制造。||可能的实体：台积电,黑芝麻智能||...  False   \n",
       "1  俊盟国际(08062) 财务报表/环境、社会及管治资料 - [年报 / 环境、社会及管治资料...  False   \n",
       "2  热辣新盘放送｜明隽首轮推售34伙 连天台特色户率先招标沽。||可能的实体：明隽||热辣新盘放...  False   \n",
       "\n",
       "                                          input_text  \\\n",
       "0  黑芝麻智能成首间特专科企申请上市 芯片依赖台积电制造。黑芝麻智能成首间特专科企申请上市 芯片...   \n",
       "1  俊盟国际(08062) 财务报表/环境、社会及管治资料 - [年报 / 环境、社会及管治资料...   \n",
       "2  热辣新盘放送｜明隽首轮推售34伙 连天台特色户率先招标沽。热辣新盘放送｜明隽首轮推售34伙 ...   \n",
       "\n",
       "                                            tag_char  \\\n",
       "0  [B-Company, I-Company, I-Company, I-Company, I...   \n",
       "1  [B-Company, I-Company, I-Company, I-Company, O...   \n",
       "2  [O, O, O, O, O, O, O, B-Company, I-Company, O,...   \n",
       "\n",
       "                                   tokenized_content  \\\n",
       "0  [黑, 芝, 麻, 智, 能, 成, 首, 间, 特, 专, 科, 企, 申, 请, 上, ...   \n",
       "1  [俊, 盟, 国, 际, (, 0, 8, 0, 6, 2, ), 财, 务, 报, 表, ...   \n",
       "2  [热, 辣, 新, 盘, 放, 送, ｜, 明, 隽, 首, 轮, 推, 售, 3, 4, ...   \n",
       "\n",
       "                                        token_labels  \n",
       "0  [B-Company, I-Company, I-Company, I-Company, I...  \n",
       "1  [B-Company, I-Company, I-Company, I-Company, O...  \n",
       "2  [O, O, O, O, O, O, O, B-Company, I-Company, O,...  "
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_valid.shape)\n",
    "df_valid = df_valid[~df_valid['tag_char'].isna()]\n",
    "print(df_valid.shape)\n",
    "df_valid = tokenize_and_align_labels(df_valid, args)\n",
    "df_valid.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove long text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    30794.000000\n",
      "mean       402.246671\n",
      "std        122.334387\n",
      "min          4.000000\n",
      "25%        387.000000\n",
      "50%        458.000000\n",
      "75%        480.000000\n",
      "max        502.000000\n",
      "Name: len_tokens, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_train['len_tokens'] = df_train['tokenized_content'].apply(lambda x: len(x))\n",
    "df_train = df_train[df_train['len_tokens'] < args.max_len-2]\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "print(df_train['len_tokens'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    4010.000000\n",
      "mean      400.301247\n",
      "std       122.649495\n",
      "min         8.000000\n",
      "25%       378.000000\n",
      "50%       458.000000\n",
      "75%       480.000000\n",
      "max       499.000000\n",
      "Name: len_tokens, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_valid['len_tokens'] = df_valid['tokenized_content'].apply(lambda x: len(x))\n",
    "df_valid = df_valid[df_valid['len_tokens'] < args.max_len-2]\n",
    "df_valid = df_valid.reset_index(drop=True)\n",
    "print(df_valid['len_tokens'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('对', 'O'), ('于', 'O'), ('先', 'O'), ('前', 'O'), ('超', 'O'), ('速', 'O'), ('扩', 'O'), ('张', 'O'), ('引', 'O'), ('发', 'O'), ('的', 'O'), ('种', 'O'), ('种', 'O'), ('问', 'O'), ('题', 'O'), ('，', 'O'), ('体', 'O'), ('育', 'O'), ('品', 'O'), ('牌', 'O'), ('巨', 'O'), ('头', 'O'), ('们', 'O'), ('无', 'O'), ('不', 'O'), ('在', 'O'), ('重', 'O'), ('新', 'O'), ('审', 'O'), ('视', 'O'), ('中', 'O'), ('国', 'O'), ('市', 'O'), ('场', 'O'), ('。', 'O'), ('新', 'O'), ('闻', 'O'), ('链', 'O'), ('接', 'O'), ('。', 'O'), ('1', 'O'), ('.', 'O'), ('6', 'O'), ('5', 'O'), ('亿', 'O'), ('收', 'O'), ('购', 'O'), ('凯', 'B-Company'), ('胜', 'I-Company'), ('李', 'O'), ('宁', 'O'), ('恋', 'O'), ('上', 'O'), ('羽', 'O'), ('毛', 'O'), ('球', 'O'), ('运', 'O'), ('动', 'O'), ('用', 'O'), ('品', 'O'), ('商', 'O'), ('李', 'O'), ('宁', 'O'), ('（', 'O'), ('0', 'O'), ('2', 'O'), ('3', 'O'), ('3', 'O'), ('1', 'O'), ('，', 'O'), ('h', 'O'), ('k', 'O'), ('）', 'O'), ('日', 'O'), ('前', 'O'), ('宣', 'O'), ('布', 'O'), ('1', 'O'), ('.', 'O'), ('6', 'O'), ('5', 'O'), ('亿', 'O'), ('元', 'O'), ('收', 'O'), ('购', 'O'), ('凯', 'B-Company'), ('胜', 'I-Company'), ('（', 'O'), ('k', 'O'), ('a', 'O'), ('s', 'O'), ('o', 'O'), ('n', 'O'), ('）', 'O'), ('品', 'O'), ('牌', 'O'), ('羽', 'O'), ('毛', 'O'), ('球', 'O'), ('拍', 'O'), ('、', 'O'), ('运', 'O'), ('动', 'O'), ('服', 'O'), ('装', 'O'), ('及', 'O'), ('运', 'O'), ('动', 'O'), ('配', 'O'), ('件', 'O'), ('等', 'O'), ('业', 'O'), ('务', 'O'), ('。', 'O'), ('这', 'O'), ('也', 'O'), ('是', 'O'), ('继', 'O'), ('两', 'O'), ('个', 'O'), ('月', 'O'), ('前', 'O'), ('成', 'O'), ('为', 'O'), ('中', 'B-Company'), ('国', 'I-Company'), ('国', 'I-Company'), ('家', 'I-Company'), ('羽', 'I-Company'), ('毛', 'I-Company'), ('球', 'I-Company'), ('队', 'I-Company'), ('赞', 'O'), ('助', 'O'), ('商', 'O'), ('后', 'O'), ('，', 'O'), ('李', 'O'), ('宁', 'O'), ('在', 'O'), ('羽', 'O'), ('毛', 'O'), ('球', 'O'), ('专', 'O'), ('业', 'O'), ('领', 'O'), ('域', 'O'), ('的', 'O'), ('再', 'O'), ('次', 'O'), ('大', 'O'), ('手', 'O'), ('笔', 'O'), ('投', 'O'), ('入', 'O'), ('。', 'O'), ('公', 'O'), ('开', 'O'), ('资', 'O'), ('料', 'O'), ('显', 'O'), ('示', 'O'), ('，', 'O'), ('创', 'O'), ('立', 'O'), ('于', 'O'), ('1', 'O'), ('9', 'O'), ('9', 'O'), ('1', 'O'), ('年', 'O'), ('的', 'O'), ('凯', 'B-Company'), ('胜', 'I-Company'), ('品', 'O'), ('牌', 'O'), ('是', 'O'), ('目', 'O'), ('前', 'O'), ('中', 'O'), ('国', 'O'), ('羽', 'O'), ('毛', 'O'), ('球', 'O'), ('器', 'O'), ('材', 'O'), ('市', 'O'), ('场', 'O'), ('的', 'O'), ('三', 'O'), ('大', 'O'), ('品', 'O'), ('牌', 'O'), ('之', 'O'), ('一', 'O'), ('，', 'O'), ('李', 'O'), ('宁', 'O'), ('此', 'O'), ('次', 'O'), ('将', 'O'), ('收', 'O'), ('购', 'O'), ('凯', 'B-Company'), ('胜', 'I-Company'), ('品', 'O'), ('牌', 'O'), ('各', 'O'), ('产', 'O'), ('品', 'O'), ('的', 'O'), ('研', 'O'), ('发', 'O'), ('、', 'O'), ('制', 'O'), ('造', 'O'), ('及', 'O'), ('营', 'O'), ('销', 'O'), ('部', 'O'), ('门', 'O'), ('。', 'O'), ('相', 'O'), ('关', 'O'), ('人', 'O'), ('士', 'O'), ('曾', 'O'), ('表', 'O'), ('示', 'O'), ('，', 'O'), ('8', 'O'), ('年', 'O'), ('前', 'O'), ('，', 'O'), ('李', 'O'), ('宁', 'O'), ('就', 'O'), ('有', 'O'), ('赞', 'O'), ('助', 'O'), ('羽', 'O'), ('毛', 'O'), ('球', 'O'), ('赛', 'O'), ('事', 'O'), ('的', 'O'), ('想', 'O'), ('法', 'O'), ('。', 'O'), ('据', 'O'), ('悉', 'O'), ('，', 'O'), ('李', 'B-Company'), ('宁', 'I-Company'), ('公', 'I-Company'), ('司', 'I-Company'), ('在', 'O'), ('2', 'O'), ('0', 'O'), ('0', 'O'), ('7', 'O'), ('年', 'O'), ('就', 'O'), ('开', 'O'), ('始', 'O'), ('了', 'O'), ('对', 'O'), ('羽', 'O'), ('毛', 'O'), ('球', 'O'), ('市', 'O'), ('场', 'O'), ('的', 'O'), ('调', 'O'), ('研', 'O'), ('。', 'O'), ('据', 'O'), ('李', 'B-Company'), ('宁', 'I-Company'), ('公', 'I-Company'), ('司', 'I-Company'), ('内', 'O'), ('部', 'O'), ('人', 'O'), ('士', 'O'), ('透', 'O'), ('露', 'O'), ('，', 'O'), ('李', 'O'), ('宁', 'O'), ('收', 'O'), ('购', 'O'), ('凯', 'B-Company'), ('胜', 'I-Company'), ('品', 'O'), ('牌', 'O'), ('，', 'O'), ('在', 'O'), ('去', 'O'), ('年', 'O'), ('年', 'O'), ('底', 'O'), ('就', 'O'), ('已', 'O'), ('完', 'O'), ('成', 'O'), ('，', 'O'), ('[UNK]', 'O'), ('在', 'O'), ('李', 'O'), ('宁', 'O'), ('举', 'O'), ('行', 'O'), ('的', 'O'), ('新', 'O'), ('季', 'O'), ('订', 'O'), ('货', 'O'), ('会', 'O'), ('上', 'O'), ('，', 'O'), ('许', 'O'), ('多', 'O'), ('原', 'O'), ('凯', 'B-Company'), ('胜', 'I-Company'), ('品', 'O'), ('牌', 'O'), ('的', 'O'), ('经', 'O'), ('销', 'O'), ('商', 'O'), ('都', 'O'), ('出', 'O'), ('席', 'O'), ('了', 'O'), ('。', 'O'), ('[UNK]', 'O'), ('这', 'O'), ('几', 'O'), ('年', 'O'), ('，', 'O'), ('李', 'O'), ('宁', 'O'), ('在', 'O'), ('多', 'O'), ('品', 'O'), ('牌', 'O'), ('经', 'O'), ('营', 'O'), ('之', 'O'), ('路', 'O'), ('上', 'O'), ('动', 'O'), ('作', 'O'), ('频', 'O'), ('频', 'O'), ('，', 'O'), ('形', 'O'), ('成', 'O'), ('了', 'O'), ('一', 'O'), ('个', 'O'), ('主', 'O'), ('品', 'O'), ('牌', 'O'), ('，', 'O'), ('多', 'O'), ('个', 'O'), ('副', 'O'), ('品', 'O'), ('牌', 'O'), ('的', 'O'), ('多', 'O'), ('品', 'O'), ('牌', 'O'), ('经', 'O'), ('营', 'O'), ('战', 'O'), ('略', 'O'), ('。', 'O'), ('但', 'O'), ('李', 'O'), ('宁', 'O'), ('2', 'O'), ('0', 'O'), ('0', 'O'), ('8', 'O'), ('年', 'O'), ('的', 'O'), ('财', 'O'), ('务', 'O'), ('报', 'O'), ('表', 'O'), ('披', 'O'), ('露', 'O'), ('，', 'O'), ('李', 'O'), ('宁', 'O'), ('主', 'O'), ('品', 'O'), ('牌', 'O'), ('的', 'O'), ('销', 'O'), ('售', 'O'), ('收', 'O'), ('入', 'O'), ('仍', 'O'), ('占', 'O'), ('公', 'O'), ('司', 'O'), ('整', 'O'), ('个', 'O'), ('产', 'O'), ('品', 'O'), ('的', 'O'), ('比', 'O'), ('例', 'O'), ('高', 'O'), ('达', 'O'), ('9', 'O'), ('5', 'O'), ('%', 'O'), ('以', 'O'), ('上', 'O'), ('。', 'O'), ('分', 'O'), ('析', 'O'), ('人', 'O'), ('士', 'O'), ('指', 'O'), ('出', 'O'), ('，', 'O'), ('李', 'O'), ('宁', 'O'), ('的', 'O'), ('多', 'O'), ('品', 'O'), ('牌', 'O'), ('运', 'O'), ('作', 'O'), ('的', 'O'), ('主', 'O'), ('要', 'O'), ('特', 'O'), ('点', 'O'), ('是', 'O'), ('依', 'O'), ('托', 'O'), ('李', 'B-Company'), ('宁', 'I-Company'), ('公', 'I-Company'), ('司', 'I-Company'), ('没', 'O'), ('有', 'O'), ('生', 'O'), ('产', 'O'), ('线', 'O'), ('的', 'O'), ('[UNK]', 'O'), ('轻', 'O'), ('资', 'O'), ('产', 'O'), ('[UNK]', 'O'), ('特', 'O'), ('点', 'O'), ('，', 'O'), ('完', 'O'), ('全', 'O'), ('集', 'O'), ('中', 'O'), ('在', 'O'), ('产', 'O'), ('品', 'O'), ('研', 'O'), ('发', 'O'), ('和', 'O'), ('多', 'O'), ('品', 'O'), ('牌', 'O'), ('管', 'O'), ('理', 'O'), ('的', 'O'), ('核', 'O'), ('心', 'O'), ('业', 'O'), ('务', 'O'), ('上', 'O')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30794, 21)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(zip(df_train.loc[10300, 'tokenized_content'], df_train.loc[10300, 'token_labels'])))\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('作', 'O'), ('者', 'O'), ('p', 'O'), ('d', 'O'), ('s', 'O'), ('1', 'O'), ('(', 'O'), ('f', 'O'), ('i', 'O'), ('g', 'O'), ('h', 'O'), ('t', 'O'), ('e', 'O'), ('r', 'O'), (')', 'O'), ('。', 'O'), ('看', 'O'), ('板', 'O'), ('h', 'O'), ('o', 'O'), ('m', 'O'), ('e', 'O'), ('-', 'O'), ('s', 'O'), ('a', 'O'), ('l', 'O'), ('e', 'O'), ('。', 'O'), ('标', 'O'), ('题', 'O'), ('[', 'O'), ('新', 'O'), ('闻', 'O'), (']', 'O'), ('宏', 'O'), ('盛', 'O'), ('董', 'O'), ('事', 'O'), ('长', 'O'), ('林', 'B-Person'), ('祖', 'I-Person'), ('郁', 'I-Person'), ('︰', 'O'), ('房', 'O'), ('价', 'O'), ('难', 'O'), ('有', 'O'), ('调', 'O'), ('降', 'O'), ('空', 'O'), ('间', 'O'), ('。', 'O'), ('时', 'O'), ('间', 'O'), ('s', 'O'), ('a', 'O'), ('t', 'O'), ('j', 'O'), ('u', 'O'), ('n', 'O'), ('2', 'O'), ('7', 'O'), ('1', 'O'), ('3', 'O'), (':', 'O'), ('1', 'O'), ('8', 'O'), (':', 'O'), ('5', 'O'), ('5', 'O'), ('2', 'O'), ('0', 'O'), ('1', 'O'), ('5', 'O'), ('。', 'O'), ('内', 'O'), ('文', 'O'), (':', 'O'), ('2', 'O'), ('0', 'O'), ('1', 'O'), ('5', 'O'), ('-', 'O'), ('0', 'O'), ('6', 'O'), ('-', 'O'), ('2', 'O'), ('5', 'O'), ('〔', 'O'), ('记', 'O'), ('者', 'O'), ('陈', 'O'), ('永', 'O'), ('吉', 'O'), ('/', 'O'), ('台', 'O'), ('北', 'O'), ('报', 'O'), ('导', 'O'), ('〕', 'O'), ('房', 'O'), ('地', 'O'), ('产', 'O'), ('景', 'O'), ('气', 'O'), ('众', 'O'), ('说', 'O'), ('纷', 'O'), ('纭', 'O'), (',', 'O'), ('宏', 'O'), ('盛', 'O'), ('董', 'O'), ('事', 'O'), ('长', 'O'), ('林', 'B-Person'), ('祖', 'I-Person'), ('郁', 'I-Person'), ('昨', 'O'), ('天', 'O'), ('表', 'O'), ('示', 'O'), (',', 'O'), ('房', 'O'), ('市', 'O'), ('总', 'O'), ('有', 'O'), ('景', 'O'), ('气', 'O'), ('循', 'O'), ('环', 'O'), (',', 'O'), ('但', 'O'), ('这', 'O'), ('波', 'O'), ('要', 'O'), ('向', 'O'), ('下', 'O'), ('多', 'O'), ('久', 'O'), (',', 'O'), ('[UNK]', 'O'), ('没', 'O'), ('师', 'O'), ('傅', 'O'), ('[UNK]', 'O'), ('(', 'O'), ('指', 'O'), ('没', 'O'), ('人', 'O'), ('说', 'O'), ('得', 'O'), ('准', 'O'), (')', 'O'), ('。', 'O'), ('不', 'O'), ('过', 'O'), ('因', 'O'), ('土', 'O'), ('地', 'O'), ('成', 'O'), ('本', 'O'), ('没', 'O'), ('降', 'O'), ('、', 'O'), ('容', 'O'), ('积', 'O'), ('率', 'O'), ('又', 'O'), ('被', 'O'), ('政', 'O'), ('府', 'O'), ('限', 'O'), ('缩', 'O'), ('、', 'O'), ('公', 'O'), ('告', 'O'), ('现', 'O'), ('值', 'O'), ('也', 'O'), ('增', 'O'), ('加', 'O'), (',', 'O'), ('这', 'O'), ('些', 'O'), ('成', 'O'), ('本', 'O'), ('都', 'O'), ('反', 'O'), ('映', 'O'), ('在', 'O'), ('房', 'O'), ('价', 'O'), ('里', 'O'), (',', 'O'), ('所', 'O'), ('以', 'O'), ('房', 'O'), ('价', 'O'), ('很', 'O'), ('难', 'O'), ('有', 'O'), ('降', 'O'), ('价', 'O'), ('空', 'O'), ('间', 'O'), ('。', 'O'), ('他', 'O'), ('话', 'O'), ('锋', 'O'), ('一', 'O'), ('转', 'O'), (',', 'O'), ('严', 'O'), ('批', 'O'), ('政', 'O'), ('府', 'O'), ('一', 'O'), ('方', 'O'), ('面', 'O'), ('高', 'O'), ('喊', 'O'), ('居', 'O'), ('住', 'O'), ('正', 'O'), ('义', 'O'), (',', 'O'), ('另', 'O'), ('一', 'O'), ('方', 'O'), ('面', 'O'), ('不', 'O'), ('断', 'O'), ('增', 'O'), ('加', 'O'), ('房', 'O'), ('地', 'O'), ('产', 'O'), ('相', 'O'), ('关', 'O'), ('税', 'O'), ('目', 'O'), (',', 'O'), ('而', 'O'), ('且', 'O'), ('国', 'O'), ('有', 'O'), ('地', 'O'), ('、', 'O'), ('联', 'O'), ('开', 'O'), ('案', 'O'), ('分', 'O'), ('到', 'O'), ('的', 'O'), ('住', 'O'), ('宅', 'O'), ('拿', 'O'), ('出', 'O'), ('来', 'O'), ('标', 'O'), ('售', 'O'), (',', 'O'), ('定', 'O'), ('价', 'O'), ('又', 'O'), ('这', 'O'), ('么', 'O'), ('高', 'O'), (',', 'O'), ('房', 'O'), ('价', 'O'), ('要', 'O'), ('怎', 'O'), ('么', 'O'), ('下', 'O'), ('跌', 'O'), (',', 'O'), ('根', 'O'), ('本', 'O'), ('就', 'O'), ('是', 'O'), ('政', 'O'), ('策', 'O'), ('自', 'O'), ('相', 'O'), ('矛', 'O'), ('盾', 'O'), ('。', 'O'), ('他', 'O'), ('还', 'O'), ('说', 'O'), (',', 'O'), ('宏', 'B-Company'), ('盛', 'I-Company'), ('建', 'I-Company'), ('设', 'I-Company'), ('跟', 'O'), ('宏', 'B-Company'), ('泰', 'I-Company'), ('人', 'I-Company'), ('寿', 'I-Company'), ('共', 'O'), ('同', 'O'), ('投', 'O'), ('资', 'O'), ('兴', 'O'), ('建', 'O'), ('的', 'O'), ('[UNK]', 'O'), ('宏', 'B-Company'), ('盛', 'I-Company'), ('国', 'I-Company'), ('际', 'I-Company'), ('金', 'I-Company'), ('融', 'I-Company'), ('中', 'I-Company'), ('心', 'I-Company'), ('[UNK]', 'O'), (',', 'O'), ('当', 'O'), ('初', 'O'), ('土', 'O'), ('地', 'O'), ('是', 'O'), ('两', 'O'), ('家', 'O'), ('公', 'O'), ('司', 'O'), ('共', 'O'), ('同', 'O'), ('持', 'O'), ('有', 'O'), (',', 'O'), ('政', 'O'), ('府', 'O'), ('无', 'O'), ('持', 'O'), ('份', 'O'), (',', 'O'), ('只', 'O'), ('因', 'O'), ('捷', 'O'), ('运', 'O'), ('出', 'O'), ('口', 'O'), ('从', 'O'), ('地', 'O'), ('上', 'O'), ('通', 'O'), ('过', 'O'), (',', 'O'), ('却', 'O'), ('强', 'O'), ('制', 'O'), ('要', 'O'), ('联', 'O'), ('合', 'O'), ('开', 'O'), ('发', 'O'), (',', 'O'), ('否', 'O'), ('则', 'O'), ('要', 'O'), ('强', 'O'), ('制', 'O'), ('征', 'O'), ('收', 'O'), ('土', 'O'), ('地', 'O'), (',', 'O'), ('而', 'O'), ('且', 'O'), ('兴', 'O'), ('建', 'O'), ('完', 'O'), ('成', 'O'), ('后', 'O'), (',', 'O'), ('整', 'O'), ('栋', 'O'), ('楼', 'O'), ('让', 'O'), ('政', 'O'), ('府', 'O'), ('自', 'O'), ('己', 'O'), ('选', 'O'), ('喜', 'O'), ('欢', 'O'), ('的', 'O'), ('单', 'O'), ('位', 'O'), (',', 'O'), ('却', 'O'), ('选', 'O'), ('了', 'O'), ('1', 'O'), ('年', 'O'), (',', 'O'), ('一', 'O'), ('直', 'O'), ('到', 'O'), ('今', 'O'), ('年', 'O'), ('初', 'O'), ('产', 'O'), ('权', 'O'), ('才', 'O'), ('完', 'O'), ('成', 'O'), ('登', 'O'), ('记', 'O'), (',', 'O'), ('拖', 'O'), ('到', 'O'), ('房', 'O'), ('市', 'O'), ('景', 'O'), ('气', 'O'), ('从', 'O'), ('好', 'O'), ('变', 'O'), ('成', 'O'), ('不', 'O'), ('好', 'O'), (',', 'O'), ('否', 'O'), ('则', 'O'), ('说', 'O'), ('不', 'O'), ('定', 'O'), ('早', 'O'), ('就', 'O'), ('卖', 'O'), ('掉', 'O'), ('了', 'O')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4010, 21)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(zip(df_valid.loc[1310, 'tokenized_content'], df_valid.loc[1310, 'token_labels'])))\n",
    "df_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 统计有公司的文本量和有人名的文本量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28700, 21) (25669, 21) Index(['docid', 'headline', 'content', 'ner', 'matched_keywords',\n",
      "       'include_company', 'include_person', 'length', 'split_sentence_index',\n",
      "       'Companys', 'Persons', 'context_cleaned', 'person_matched',\n",
      "       'company_matched', 'context_keywords', 'sign', 'input_text', 'tag_char',\n",
      "       'tokenized_content', 'token_labels', 'len_tokens'],\n",
      "      dtype='object')\n",
      "(3727, 21) (3348, 21) Index(['docid', 'headline', 'content', 'ner', 'matched_keywords',\n",
      "       'include_company', 'include_person', 'length', 'split_sentence_index',\n",
      "       'Companys', 'Persons', 'context_cleaned', 'person_matched',\n",
      "       'company_matched', 'context_keywords', 'sign', 'input_text', 'tag_char',\n",
      "       'tokenized_content', 'token_labels', 'len_tokens'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_train[df_train['include_company']==True].shape, df_train[df_train['include_person']==True].shape, df_train.columns)\n",
    "print(df_valid[df_valid['include_company']==True].shape, df_valid[df_valid['include_person']==True].shape, df_valid.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30794, 21), (4010, 21))"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../experiments/0606_bert_p=0.5_pos=sentence_BP'"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.prefix_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.to_pickle(f\"{args.prefix_path}/train_data.pkl\")\n",
    "df_valid.to_pickle(f\"{args.prefix_path}/valid_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_pickle(f\"{args.prefix_path}/train_data.pkl\")\n",
    "# df_valid = pd.read_pickle(f\"{args.prefix_path}/valid_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, row in df_train.iterrows():\n",
    "    if \"peets\" in row['input_text'].lower():\n",
    "        print(row['input_text'])\n",
    "        for i, j in zip(row['tokenized_content'], row['token_labels']):\n",
    "            print(i, j)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_padding_and_mask(example):\n",
    "    tokenized_context = [tokenizer.cls_token] + example['tokenized_content'] + [tokenizer.sep_token]\n",
    "    labels = example['token_labels']\n",
    "    labels.insert(0, 'O')\n",
    "    labels.insert(len(labels), \"O\")\n",
    "\n",
    "    max_len = args.max_len\n",
    "    if len(tokenized_context) > max_len: \n",
    "        tokenized_context = tokenized_context[:max_len]\n",
    "        labels = labels[:max_len]\n",
    "    else:\n",
    "        tokenized_context = tokenized_context + [tokenizer.pad_token] * (max_len - len(tokenized_context))\n",
    "        labels = labels + ['O'] * (max_len - len(labels))\n",
    "\n",
    "    attn_mask = [1 if tok != tokenizer.pad_token else 0 for tok in tokenized_context]\n",
    "\n",
    "    ids = tokenizer.convert_tokens_to_ids(tokenized_context)\n",
    "\n",
    "    label_ids = [labels_to_ids[label] for label in labels]\n",
    "\n",
    "    return {\n",
    "          'ids': torch.tensor(ids, dtype=torch.long),\n",
    "          'masks': torch.tensor(attn_mask, dtype=torch.long),\n",
    "          'labels': torch.tensor(label_ids, dtype=torch.long)\n",
    "        } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e4b62bd5e94a40adbe48d406c774c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Map', max=30794.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(args.pretrained_model)\n",
    "\n",
    "train_dataset = datasets.Dataset.from_pandas(df_train[['docid', 'tokenized_content', 'token_labels']])\n",
    "train_dataset = train_dataset.map(add_padding_and_mask, remove_columns=['tokenized_content', 'token_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae04bcd39aea4ebfaf2dff327fc8faea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Map', max=4010.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(args.pretrained_model)\n",
    "\n",
    "valid_dataset = datasets.Dataset.from_pandas(df_valid[['docid', 'tokenized_content', 'token_labels']])\n",
    "valid_dataset = valid_dataset.map(add_padding_and_mask, remove_columns=['tokenized_content', 'token_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa516561ab048d184d2a089ed1645d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Saving the dataset (0/1 shards)', max=30794.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94dabb9388f6442e896b9e98a7128be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Saving the dataset (0/1 shards)', max=4010.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset.save_to_disk(f'{args.prefix_path}/train_dataset')\n",
    "valid_dataset.save_to_disk(f'{args.prefix_path}/valid_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets.Dataset.load_from_disk(f'{args.pre_path}/dataset/headline_content_keywords/train/train/train_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4554, 17)\n",
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27347305e7c046adbd2420e589e74452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=143), Label(value='0 / 143'))), HB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n"
     ]
    }
   ],
   "source": [
    "df_test[\"input_text\"] = df_test[\"context_cleaned\"] ## 全不加\n",
    "# df_test[\"input_text\"] = df_test[\"context_keywords\"] ## 全加keywords\n",
    "print(df_test.shape)\n",
    "pandarallel.initialize(nb_workers=32, progress_bar=True, use_memory_fs=False)\n",
    "df_test[[\"tokenized_content\", \"ids\", \"masks\"]] = df_test.parallel_apply(tokenize_test_text, param_args=args, axis=1).to_list()\n",
    "\n",
    "test_dataset = datasets.Dataset.from_pandas(df_test[[\"docid\", \"tokenized_content\", \"ids\", \"masks\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4554, 20)\n"
     ]
    }
   ],
   "source": [
    "# df_test.to_pickle(f\"{args.pre_path}/dataset/headline_content_keywords/test/test_data_{args.experiment_name}_{args.mode}.pkl\")\n",
    "print(df_test.shape)\n",
    "df_test.to_pickle(f\"{args.prefix_path}/test_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993f6027ceac43f097e1dff7f42af3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Saving the dataset (0/1 shards)', max=4554.0, style=Progr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test_dataset.save_to_disk(f'{args.pre_path}/dataset/headline_content_keywords/test/test/test_data_new-dict')\n",
    "test_dataset.save_to_disk(f'{args.prefix_path}/test_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_test.head(1).to_dict('record')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# badcase dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from zhconv import convert\n",
    "badcase_data = pd.read_excel(\"/workspace/client_project/poc/bochk/badcase/bochk_uat_20240410_ner.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(badcase_data.shape)\n",
    "# badcase_data.head(), \n",
    "set(badcase_data['doc_id'].tolist()).__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_labels(data):\n",
    "    data_list = []\n",
    "    for doc_id, groupdf in data.groupby(\"doc_id\"):\n",
    "        content = convert(str(groupdf['headline'].tolist()[0]) + \"。\" + str(groupdf['content'].tolist()[0]), 'zh-cn')\n",
    "        single_dic = {\n",
    "            \"doc_id\": doc_id, \n",
    "            \"input_text\": content,\n",
    "            \"person_matched\": list(set([row['ner_keyword'] for index, row in groupdf.iterrows() if row['ner_label_type'] == \"Person\" and row['ner_keyword'] in content])),                 \n",
    "            \"company_matched\": list(set([row['ner_keyword'] for index, row in groupdf.iterrows() if row['ner_label_type'] == \"Company\" and row['ner_keyword'] in content]))\n",
    "        }\n",
    "        data_list.append(single_dic)\n",
    "    return pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>input_text</th>\n",
       "      <th>person_matched</th>\n",
       "      <th>company_matched</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023120100000939360</td>\n",
       "      <td>英再有城市破产 诺定咸超支2.3亿。\\n继英国第二大城市伯明翰市议会9月初宣布破产后，英国中...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Nottingham]</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023120100001090313</td>\n",
       "      <td>中央谷长三角 宁沪盈利复增。  江苏宁沪高速（00177）主业务是收费路桥的投资、建设、营运...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023121900002995017</td>\n",
       "      <td>东软熙康（０９６８６）独董方唯一辞任，齐国先接任。\\n\\n 　　《经济通通讯社１９日专讯》东...</td>\n",
       "      <td>[方唯]</td>\n",
       "      <td>[]</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023122100001384938</td>\n",
       "      <td>毛记葵涌开市“唛高”近7倍。【明报专讯】向来交投淡静的毛记葵涌（1716），昨日在开市不久即...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Ken Sir]</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023122100002680716</td>\n",
       "      <td>九方财富（０９６３６）首席执行官才子辞任，主席陈文彬兼任。\\n\\n 　　《经济通通讯社２１日...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                doc_id                                         input_text  \\\n",
       "0  2023120100000939360  英再有城市破产 诺定咸超支2.3亿。\\n继英国第二大城市伯明翰市议会9月初宣布破产后，英国中...   \n",
       "1  2023120100001090313  中央谷长三角 宁沪盈利复增。  江苏宁沪高速（00177）主业务是收费路桥的投资、建设、营运...   \n",
       "2  2023121900002995017  东软熙康（０９６８６）独董方唯一辞任，齐国先接任。\\n\\n 　　《经济通通讯社１９日专讯》东...   \n",
       "3  2023122100001384938  毛记葵涌开市“唛高”近7倍。【明报专讯】向来交投淡静的毛记葵涌（1716），昨日在开市不久即...   \n",
       "4  2023122100002680716  九方财富（０９６３６）首席执行官才子辞任，主席陈文彬兼任。\\n\\n 　　《经济通通讯社２１日...   \n",
       "\n",
       "  person_matched company_matched  length  \n",
       "0             []    [Nottingham]     176  \n",
       "1             []              []     199  \n",
       "2           [方唯]              []     240  \n",
       "3             []       [Ken Sir]     465  \n",
       "4             []              []     253  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badcase_test_data = merge_labels(badcase_data)\n",
    "badcase_test_data['length'] = badcase_test_data['input_text'].map(len)\n",
    "badcase_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 5)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badcase_test_data[badcase_test_data['length']> 512].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from zhconv import convert\n",
    "import copy\n",
    "def split_sentences(text):\n",
    "    \n",
    "    sentences_ls = re.split(r'[?!;~。？！；～>\\n\\r]', text)\n",
    "    sentences = [sent for sent in sentences_ls if sent.strip() != '']\n",
    "    # sentences = list(zip(list(range(0, len(sentences))), sentences))\n",
    "    return sentences\n",
    "\n",
    "def split_single_sentence(data: pd.DataFrame, sentence_length_limit: int=500):\n",
    "    \"\"\"\n",
    "    讲文章按照句号分割成句子\n",
    "    :param data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    complete_data_list = []\n",
    "    for index, row in data.iterrows():\n",
    "        raw_single_dic = dict(row)\n",
    "        content = convert(row['content'], 'zh-cn')\n",
    "        processed_content_ls = split_sentences(content)\n",
    "        last_sentence_index = 0\n",
    "        sentence_index = 0\n",
    "        for i in range(processed_content_ls.__len__()+1):\n",
    "            # print(last_sentence_index, i)\n",
    "            text = \"。\".join(processed_content_ls[last_sentence_index:i])\n",
    "            if text.strip() != \"\":\n",
    "                if text.__len__() >= sentence_length_limit:\n",
    "                    # print(i, \"===\", text)\n",
    "                    raw_single_dic_backup = copy.copy(raw_single_dic)\n",
    "                    raw_single_dic_backup['content'] = \"。\".join(processed_content_ls[last_sentence_index:i-1])\n",
    "                    raw_single_dic_backup['split_sentence_index'] = sentence_index\n",
    "                    complete_data_list.append(raw_single_dic_backup)\n",
    "                    last_sentence_index = i -1\n",
    "                    sentence_index += 1\n",
    "                else:\n",
    "                    if i == processed_content_ls.__len__():\n",
    "                        # print(i, \"***\", text)\n",
    "                        raw_single_dic_backup = copy.copy(raw_single_dic)\n",
    "                        raw_single_dic_backup['content'] = text\n",
    "                        raw_single_dic_backup['split_sentence_index'] = sentence_index\n",
    "                        complete_data_list.append(raw_single_dic_backup)\n",
    "                        \n",
    "                    else:\n",
    "                        pass\n",
    "    return pd.DataFrame(complete_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_keyword(row):\n",
    "    companys = set()\n",
    "    person = set()\n",
    "    if isinstance(row['ner'], str):\n",
    "        ner_list = eval(row['ner'])\n",
    "    elif isinstance(row['ner'], list):\n",
    "        ner_list = row['ner']\n",
    "    # print(ner_list)\n",
    "    for dic in ner_list:\n",
    "        entity = convert(dic['text_segment'], 'zh-cn')\n",
    "        if entity in row['content']:\n",
    "            if dic['label_name']=='Company':\n",
    "                companys.add(entity)\n",
    "            elif dic['label_name']=='Person' :\n",
    "                person.add(entity) \n",
    "    return list(companys), list(person)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['doc_id', 'input_text', 'person_matched', 'company_matched', 'length',\n",
       "       'content', 'split_sentence_index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badcase_test_data['content'] = badcase_test_data['input_text']\n",
    "split_sentence_df = split_single_sentence(badcase_test_data)\n",
    "split_sentence_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_sentence_df['doc_id'] = split_sentence_df.apply(lambda row: str(row['doc_id'])+\"&&\"+str(row['split_sentence_index']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_sentence_df['length'] = split_sentence_df['content'].map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>input_text</th>\n",
       "      <th>person_matched</th>\n",
       "      <th>company_matched</th>\n",
       "      <th>length</th>\n",
       "      <th>content</th>\n",
       "      <th>split_sentence_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023120100000939360&amp;&amp;0</td>\n",
       "      <td>英再有城市破产 诺定咸超支2.3亿。\\n继英国第二大城市伯明翰市议会9月初宣布破产后，英国中...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Nottingham]</td>\n",
       "      <td>168</td>\n",
       "      <td>英再有城市破产 诺定咸超支2.3亿。继英国第二大城市伯明翰市议会9月初宣布破产后，英国中部城...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023120100001090313&amp;&amp;0</td>\n",
       "      <td>中央谷长三角 宁沪盈利复增。  江苏宁沪高速（00177）主业务是收费路桥的投资、建设、营运...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>194</td>\n",
       "      <td>中央谷长三角 宁沪盈利复增。  江苏宁沪高速（00177）主业务是收费路桥的投资、建设、营运...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023121900002995017&amp;&amp;0</td>\n",
       "      <td>东软熙康（０９６８６）独董方唯一辞任，齐国先接任。\\n\\n 　　《经济通通讯社１９日专讯》东...</td>\n",
       "      <td>[方唯]</td>\n",
       "      <td>[]</td>\n",
       "      <td>229</td>\n",
       "      <td>东软熙康（０９６８６）独董方唯一辞任，齐国先接任。 　　《经济通通讯社１９日专讯》东软熙康（...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023122100001384938&amp;&amp;0</td>\n",
       "      <td>毛记葵涌开市“唛高”近7倍。【明报专讯】向来交投淡静的毛记葵涌（1716），昨日在开市不久即...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Ken Sir]</td>\n",
       "      <td>457</td>\n",
       "      <td>毛记葵涌开市“唛高”近7倍。【明报专讯】向来交投淡静的毛记葵涌（1716），昨日在开市不久即...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023122100002680716&amp;&amp;0</td>\n",
       "      <td>九方财富（０９６３６）首席执行官才子辞任，主席陈文彬兼任。\\n\\n 　　《经济通通讯社２１日...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>242</td>\n",
       "      <td>九方财富（０９６３６）首席执行官才子辞任，主席陈文彬兼任。 　　《经济通通讯社２１日专讯》九...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   doc_id                                         input_text  \\\n",
       "0  2023120100000939360&&0  英再有城市破产 诺定咸超支2.3亿。\\n继英国第二大城市伯明翰市议会9月初宣布破产后，英国中...   \n",
       "1  2023120100001090313&&0  中央谷长三角 宁沪盈利复增。  江苏宁沪高速（00177）主业务是收费路桥的投资、建设、营运...   \n",
       "2  2023121900002995017&&0  东软熙康（０９６８６）独董方唯一辞任，齐国先接任。\\n\\n 　　《经济通通讯社１９日专讯》东...   \n",
       "3  2023122100001384938&&0  毛记葵涌开市“唛高”近7倍。【明报专讯】向来交投淡静的毛记葵涌（1716），昨日在开市不久即...   \n",
       "4  2023122100002680716&&0  九方财富（０９６３６）首席执行官才子辞任，主席陈文彬兼任。\\n\\n 　　《经济通通讯社２１日...   \n",
       "\n",
       "  person_matched company_matched  length  \\\n",
       "0             []    [Nottingham]     168   \n",
       "1             []              []     194   \n",
       "2           [方唯]              []     229   \n",
       "3             []       [Ken Sir]     457   \n",
       "4             []              []     242   \n",
       "\n",
       "                                             content  split_sentence_index  \n",
       "0  英再有城市破产 诺定咸超支2.3亿。继英国第二大城市伯明翰市议会9月初宣布破产后，英国中部城...                     0  \n",
       "1  中央谷长三角 宁沪盈利复增。  江苏宁沪高速（00177）主业务是收费路桥的投资、建设、营运...                     0  \n",
       "2  东软熙康（０９６８６）独董方唯一辞任，齐国先接任。 　　《经济通通讯社１９日专讯》东软熙康（...                     0  \n",
       "3  毛记葵涌开市“唛高”近7倍。【明报专讯】向来交投淡静的毛记葵涌（1716），昨日在开市不久即...                     0  \n",
       "4  九方财富（０９６３６）首席执行官才子辞任，主席陈文彬兼任。 　　《经济通通讯社２１日专讯》九...                     0  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6a300f1c3a4f87885db15593fadce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=3), Label(value='0 / 3'))), HBox(c…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n"
     ]
    }
   ],
   "source": [
    "split_sentence_df['input_text'] = split_sentence_df['content']\n",
    "pandarallel.initialize(nb_workers=32, progress_bar=True, use_memory_fs=False)\n",
    "split_sentence_df[[\"tokenized_content\", \"ids\", \"masks\"]] = split_sentence_df.parallel_apply(tokenize_test_text, param_args=args, axis=1).to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209d8df01a6e4dbe9c99fa1bf3e315c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Saving the dataset (0/1 shards)', max=70.0, style=Progres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "split_sentence_df['docid'] = split_sentence_df['doc_id']\n",
    "badcase_dataset = datasets.Dataset.from_pandas(split_sentence_df[[\"docid\", \"tokenized_content\", \"ids\", \"masks\"]])\n",
    "badcase_dataset.save_to_disk(f'{args.prefix_path}/badcase_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_sentence_df.to_pickle(f\"{args.prefix_path}/badcase_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>input_text</th>\n",
       "      <th>person_matched</th>\n",
       "      <th>company_matched</th>\n",
       "      <th>length</th>\n",
       "      <th>content</th>\n",
       "      <th>split_sentence_index</th>\n",
       "      <th>tokenized_content</th>\n",
       "      <th>ids</th>\n",
       "      <th>masks</th>\n",
       "      <th>docid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023120100000939360&amp;&amp;0</td>\n",
       "      <td>英再有城市破产 诺定咸超支2.3亿。继英国第二大城市伯明翰市议会9月初宣布破产后，英国中部城...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Nottingham]</td>\n",
       "      <td>168</td>\n",
       "      <td>英再有城市破产 诺定咸超支2.3亿。继英国第二大城市伯明翰市议会9月初宣布破产后，英国中部城...</td>\n",
       "      <td>0</td>\n",
       "      <td>[英, 再, 有, 城, 市, 破, 产, 诺, 定, 咸, 超, 支, 2, ., 3, ...</td>\n",
       "      <td>[101, 5739, 1086, 3300, 1814, 2356, 4788, 772,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2023120100000939360&amp;&amp;0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023120100001090313&amp;&amp;0</td>\n",
       "      <td>中央谷长三角 宁沪盈利复增。  江苏宁沪高速（00177）主业务是收费路桥的投资、建设、营运...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>194</td>\n",
       "      <td>中央谷长三角 宁沪盈利复增。  江苏宁沪高速（00177）主业务是收费路桥的投资、建设、营运...</td>\n",
       "      <td>0</td>\n",
       "      <td>[中, 央, 谷, 长, 三, 角, 宁, 沪, 盈, 利, 复, 增, 。, 江, 苏, ...</td>\n",
       "      <td>[101, 704, 1925, 6484, 7270, 676, 6235, 2123, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2023120100001090313&amp;&amp;0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023121900002995017&amp;&amp;0</td>\n",
       "      <td>东软熙康（０９６８６）独董方唯一辞任，齐国先接任。 　　《经济通通讯社１９日专讯》东软熙康（...</td>\n",
       "      <td>[方唯]</td>\n",
       "      <td>[]</td>\n",
       "      <td>229</td>\n",
       "      <td>东软熙康（０９６８６）独董方唯一辞任，齐国先接任。 　　《经济通通讯社１９日专讯》东软熙康（...</td>\n",
       "      <td>0</td>\n",
       "      <td>[东, 软, 熙, 康, （, ０, ９, ６, ８, ６, ）, 独, 董, 方, 唯, ...</td>\n",
       "      <td>[101, 691, 6763, 4224, 2434, 8020, 8028, 8037,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2023121900002995017&amp;&amp;0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023122100001384938&amp;&amp;0</td>\n",
       "      <td>毛记葵涌开市“唛高”近7倍。【明报专讯】向来交投淡静的毛记葵涌（1716），昨日在开市不久即...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Ken Sir]</td>\n",
       "      <td>457</td>\n",
       "      <td>毛记葵涌开市“唛高”近7倍。【明报专讯】向来交投淡静的毛记葵涌（1716），昨日在开市不久即...</td>\n",
       "      <td>0</td>\n",
       "      <td>[毛, 记, 葵, 涌, 开, 市, “, 唛, 高, ”, 近, 7, 倍, 。, 【, ...</td>\n",
       "      <td>[101, 3688, 6381, 5878, 3869, 2458, 2356, 100,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2023122100001384938&amp;&amp;0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023122100002680716&amp;&amp;0</td>\n",
       "      <td>九方财富（０９６３６）首席执行官才子辞任，主席陈文彬兼任。 　　《经济通通讯社２１日专讯》九...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>242</td>\n",
       "      <td>九方财富（０９６３６）首席执行官才子辞任，主席陈文彬兼任。 　　《经济通通讯社２１日专讯》九...</td>\n",
       "      <td>0</td>\n",
       "      <td>[九, 方, 财, 富, （, ０, ９, ６, ３, ６, ）, 首, 席, 执, 行, ...</td>\n",
       "      <td>[101, 736, 3175, 6568, 2168, 8020, 8028, 8037,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2023122100002680716&amp;&amp;0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   doc_id                                         input_text  \\\n",
       "0  2023120100000939360&&0  英再有城市破产 诺定咸超支2.3亿。继英国第二大城市伯明翰市议会9月初宣布破产后，英国中部城...   \n",
       "1  2023120100001090313&&0  中央谷长三角 宁沪盈利复增。  江苏宁沪高速（00177）主业务是收费路桥的投资、建设、营运...   \n",
       "2  2023121900002995017&&0  东软熙康（０９６８６）独董方唯一辞任，齐国先接任。 　　《经济通通讯社１９日专讯》东软熙康（...   \n",
       "3  2023122100001384938&&0  毛记葵涌开市“唛高”近7倍。【明报专讯】向来交投淡静的毛记葵涌（1716），昨日在开市不久即...   \n",
       "4  2023122100002680716&&0  九方财富（０９６３６）首席执行官才子辞任，主席陈文彬兼任。 　　《经济通通讯社２１日专讯》九...   \n",
       "\n",
       "  person_matched company_matched  length  \\\n",
       "0             []    [Nottingham]     168   \n",
       "1             []              []     194   \n",
       "2           [方唯]              []     229   \n",
       "3             []       [Ken Sir]     457   \n",
       "4             []              []     242   \n",
       "\n",
       "                                             content  split_sentence_index  \\\n",
       "0  英再有城市破产 诺定咸超支2.3亿。继英国第二大城市伯明翰市议会9月初宣布破产后，英国中部城...                     0   \n",
       "1  中央谷长三角 宁沪盈利复增。  江苏宁沪高速（00177）主业务是收费路桥的投资、建设、营运...                     0   \n",
       "2  东软熙康（０９６８６）独董方唯一辞任，齐国先接任。 　　《经济通通讯社１９日专讯》东软熙康（...                     0   \n",
       "3  毛记葵涌开市“唛高”近7倍。【明报专讯】向来交投淡静的毛记葵涌（1716），昨日在开市不久即...                     0   \n",
       "4  九方财富（０９６３６）首席执行官才子辞任，主席陈文彬兼任。 　　《经济通通讯社２１日专讯》九...                     0   \n",
       "\n",
       "                                   tokenized_content  \\\n",
       "0  [英, 再, 有, 城, 市, 破, 产, 诺, 定, 咸, 超, 支, 2, ., 3, ...   \n",
       "1  [中, 央, 谷, 长, 三, 角, 宁, 沪, 盈, 利, 复, 增, 。, 江, 苏, ...   \n",
       "2  [东, 软, 熙, 康, （, ０, ９, ６, ８, ６, ）, 独, 董, 方, 唯, ...   \n",
       "3  [毛, 记, 葵, 涌, 开, 市, “, 唛, 高, ”, 近, 7, 倍, 。, 【, ...   \n",
       "4  [九, 方, 财, 富, （, ０, ９, ６, ３, ６, ）, 首, 席, 执, 行, ...   \n",
       "\n",
       "                                                 ids  \\\n",
       "0  [101, 5739, 1086, 3300, 1814, 2356, 4788, 772,...   \n",
       "1  [101, 704, 1925, 6484, 7270, 676, 6235, 2123, ...   \n",
       "2  [101, 691, 6763, 4224, 2434, 8020, 8028, 8037,...   \n",
       "3  [101, 3688, 6381, 5878, 3869, 2458, 2356, 100,...   \n",
       "4  [101, 736, 3175, 6568, 2168, 8020, 8028, 8037,...   \n",
       "\n",
       "                                               masks                   docid  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  2023120100000939360&&0  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  2023120100001090313&&0  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  2023121900002995017&&0  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  2023122100001384938&&0  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  2023122100002680716&&0  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_sentence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_sentence_df[[\"doc_id\", \"content\", \"person_matched\", \"company_matched\", \"split_sentence_index\"]].to_csv(\"entity_ner.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
